{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJkG0Iw82Babhb4UO5l8ET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danisa-R/Credit-Card-Fraud-Detector/blob/main/drunk_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRG3EfPup93s",
        "outputId": "d6ec6662-688d-4cca-ae71-5fd35e82588f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5 & cd yolov5 && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Wl8zJZq7mp",
        "outputId": "59360135-8b8b-4e20-e05b-df77900dd900"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: yolov5: No such file or directory\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15287, done.\u001b[K\n",
            "remote: Total 15287 (delta 0), reused 0 (delta 0), pack-reused 15287\u001b[K\n",
            "Receiving objects: 100% (15287/15287), 14.18 MiB | 12.94 MiB/s, done.\n",
            "Resolving deltas: 100% (10489/10489), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HMYG61NIR9b6"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s') # load pretained torchub model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bktHUdJJtUV3",
        "outputId": "7c7d1981-ff69-4ce8-c9ed-f65f1fb99b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"gitpython>=3.1.30\" \"setuptools>=65.5.1\" not found, attempting AutoUpdate...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "0NM-9BSfu0bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detect Image** "
      ],
      "metadata": {
        "id": "5aLr3ctPvp0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = '/content/daddy_trudeau.jpeg'"
      ],
      "metadata": {
        "id": "ayZH2fQDu0i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(image)\n",
        "results.print()"
      ],
      "metadata": {
        "id": "V24-399SwE90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Bsovr4Bvs_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.imshow(np.squeeze(results.render()))\n",
        "plt.show"
      ],
      "metadata": {
        "id": "PznepJB_u0lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SucxddsPhOmj"
      },
      "outputs": [],
      "source": [
        "# need to access google colab specific API -- Colab code exectures on a VM that doesn't have webcam attached \n",
        "# (APIs that presume direct hardware access won't work)\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detect thru video** "
      ],
      "metadata": {
        "id": "GbrgM2tQcUex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import os\n",
        "import time\n",
        "\n",
        "PATH_IMAGES = os.path.join('data', 'images') # return type: /data/images\n",
        "labels = ['drunk', 'not drunk']\n",
        "number_images = 20\n",
        "\n",
        "# loop thru labels then loop thru images then take a picture to save inside data folder\n",
        "video = cv2.VideoCapture(2) \n",
        "for label in labels:\n",
        "  print(\"Collecting images for f\"{labels})\n",
        "  image_name=os.path.join(PATH_IMAGES, label+'.'+str(uuid.uuid1()+'.jpg'))\n",
        "\n",
        "# saves an image to file b/c When working with OpenCV, images are stored in numpy ndarray\n",
        "  for image_num in range(number_images):\n",
        "    print(\"Collecting images for f\"{label}\" and f\"{image_num}\")\n",
        "\n",
        "    # webcam feed\n",
        "    check, frame = cap.read() \n",
        "\n",
        "    # writes out image to file\n",
        "    cv2.imwrite(image_name, frame)\n",
        "\n",
        "    # render to the screen\n",
        "    cv2.imshow('Image Collection', frame) \n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "    # 2 sec delay between image captures\n",
        "  if key & 0xFF == ord('q'): # hit 'q' on keyboard to quit\n",
        "      break\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "# TODO: might not use webcam to access data points, only use \n",
        "# access webcam\n",
        "# while video.isOpened():\n",
        "#   check, frame = video.read()\n",
        "#   cv2.imshow('YOLO', frame)\n",
        "\n",
        "#   # Make detecions\n",
        "#   results=model(frame)\n",
        "\n",
        "#   cv2.imshow('Color Frame', np.squeeze(results.render()))\n",
        "\n",
        "#   # if check:\n",
        "#   key = cv2.waitKey(10)\n",
        "#   if key & 0xFF == ord('q'): # hit 'q' on keyboard to quit\n",
        "#       break\n",
        "#   # else:\n",
        "#   #   print('Frame not available')\n",
        "#   #   print(video.isOpened())\n",
        "\n",
        "# video.release()\n",
        "# cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "8GZp05rKyqUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  "
      ],
      "metadata": {
        "id": "OTOTerkfezQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}